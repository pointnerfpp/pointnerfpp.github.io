<link rel="stylesheet" type="text/css" href="./resources/style.css" media="screen" />
<link rel="stylesheet" href="resources/dics.original.css">

<html lang="en">

<head>
    <title>
        PointNeRF++: A multi-scale, point-based Neural Radiance Field. 
    </title>
    <meta property="og:title"
        content="PointNeRF++: A multi-scale, point-based Neural Radiance Field." />
    <meta property="og:image" content="./resources/kitti360_quali_dense/output_stacked_all.mp4"/>
  	<meta property="og:description" content="
    A multi-scale, point-based neural radiance field that allows for leveraging point cloud regardless of it's low quality (e.g., LIDAR with large incomplete space)." />
    <style>
        body {
            text-align: center;
            background-color: #f0f0f0; /* Optional: Set a background color for better visibility */
        }
        .larger-arrow {
            font-size: 2.0em; /* Adjust the font size as needed */
            letter-spacing: 4.0em; /* Adjust the letter spacing as needed */
            display: inline-block; /* Ensures text-align works */
        }
    </style> 
    <script src="resources/js/video_comparison.js"></script>    
    <script src="resources/js/dics.original.js"></script>
</head>

<body>
    <div class="container">
        <div class="title">
            PointNeRF++: A multi-scale, point-based Neural Radiance Field. 
        </div>

        <div class="venue">
            ArXiv 
        </div>

        <br><br>

        <div class="author">
            <a href="http://wsunid.github.io" target="_blank">Weiwei Sun</a> <sup>1</sup> 
        </div>
        <div class="author">
            <a href="https://etrulls.github.io" target="_blank">Eduard Trulls</a> <sup>2</sup>
        </div>
        <div class="author">
            <a href="https://pointnerfpp.github.io/" target="_blank">Yang-Che Tseng</a> <sup>1</sup>  
        </div>
        <div class="author">
            <a href="https://pointnerfpp.github.io/" target="_blank">Sneha Sambandam</a> <sup>1</sup> 
        </div>

        <div class="author">
            <a href="https://hippogriff.github.io/" target="_blank">Gopal Sharma</a> <sup>1</sup> 
        </div>

        <div class="author">
            <a href="https://taiya.github.io" target="_blank">Andrea Tagliasacchi</a> <sup>3 4 5</sup>
        </div>
        <div class="author">
            <a href="https://www.cs.ubc.ca/~kmyi" target="_blank">Kwang Moo Yi</a> <sup>1</sup> 
        </div>
    
        <br><br> 
        <div class="affiliation"><sup>1</sup> University of British Columbia </div>
        <div class="affiliation"><sup>2</sup> Google Research</div>
        <div class="affiliation"><sup>3</sup> Google DeepMind </div>
        <div class="affiliation"><sup>4</sup> Simon Fraser University</div> 
        <div class="affiliation"><sup>5</sup> University of Toronto</div>  
        <br><br>
        <br>
        <div class="links"><a href="resources/paper.pdf">[Paper]</a></div>
        <div class="links"><a href="https://pointnerfpp.github.io/">[Video]</a></div>
        <div class="links"><a href="https://pointnerfpp.github.io/">[Code]</a></div>
        <div class="links"><a href="https://pointnerfpp.github.io/">[ArXiv]</a></div>
        <br><br>

        <hr>
        <br>
        <p style="width: 80%;">
            <b>TL;DR:</b>
            A multi-scale, point-based neural radiance field that allows for leveraging point cloud regardless of it's low quality (e.g., LIDAR with large incomplete space).  
        </p>
        <br> 
        <div class="parent-video-compare-container">
            <div class="video-compare-container" id="materialsDiv">
                <video class="video" id="materials" loop playsinline autoPlay muted
                  src="./resources/kitti360_compare/output_compressed.mp4" onplay="resizeAndPlay(this)"></video>
                <canvas height=0 class="videoMerge" id="materialsMerge"></canvas>
            </div>
        </div>
        <br> 
        <br> 
        <p style="width: 80%;">
            Note: Trained with sparsely sampled frames from KITTI-360 dataset and rendered with densely interpolated frames. 
        </p>
        <br> 
        <hr>
        <h1>Paper</h1>
            <div class="paper-thumbnail">
                <a href="resources/paper.pdf">
                    <img class="layered-paper-big" width="100%" src="./resources/paper.png" alt="Paper thumbnail"/>
                </a>
            </div>
            <div class="paper-info">
                <h3>PointNeRF++: A multi-scale, point-based Neural Radiance Field.</h3>
                <p>Weiwei Sun, Eduard Trulls, Yang-Che Tseng, Sneha Sambandam, Gopal Sharma, Andrea Tagliasacchi, Kwang Moo Yi</p>
                <p>arXiv.</p>
                <pre><code>@InProceedings{sun2023pointnerfpp,
                title = {PointNeRF++: A multi-scale, point-based Neural Radiance Field},
                author = {Weiwei Sun, Eduard Trulls, Yang-Che Tseng, Sneha Sambandam, Gopal Sharma, Andrea Tagliasacchi, Kwang Moo Yi},
                booktitle = {arXiv},
                year = {2023}}
                </code></pre>
            </div>
        <br>
        <hr>
        <h1>Abstract</h1>
        <p style="width: 80%;text-align: justify;">
            Point clouds offer an attractive source of information to complement images in neural scene representations, 
            especially when few images are available. Neural rendering methods based on point clouds do exist, 
            but they do not perform well when the point cloud quality is low---e.g., sparse or incomplete, 
            which is often the case with real-world data. 
            We overcome these problems with a simple representation that aggregates point clouds at multiple scale levels with sparse voxel grids at different resolutions. 
            To deal with point cloud sparsity, we average across multiple scale levels---but only among those that are valid, i.e., 
            that have enough neighboring points in proximity to the ray of a pixel. To help model areas without points, we add a global voxel at the coarsest scale, 
            thus unifying ``classical'' and point-based NeRF formulations.
        </p>
        <br>    
        <hr>
        <h1>Method</h1>
        <img style="width: 80%;" src="resources/overview.png" alt="Method Overview" />
        <br><br>
        <p style="width: 80%;text-align: justify;">
        <b>Overview</b>: given an input point cloud, we aggregate it over multi-scale voxel grids. For clarity, we draw the voxel grids in 2D.
        We then perform volume rendering based on points, relying on feature vectors stored thereon, which we aggregate across multiple scales.
        Importantly, when aggregating across scales, we only take into account 'valid' scales---denoted with the <font color="blue"> solid lines </font>  
        and illustrated as the two overlaid scales in the middle ---naturally dealing with incomplete/sparse point clouds.
        The coarsest scale is a single, global voxel, equivalent to standard NeRF (i.e., not point-based).
        </p>
        <br>
        <hr>
        <h1>Nerf <font color="red">vs</font> PointNeRF <font color="red">vs</font> PointNerf++(ours)</h1>
        <p style="width: 80%; text-align: justify;">
            We compare PointNeRF++(ours) with baselines including NeRF and PointNeRF. We show that our method achieve significantly better results than both baselines. 
            Note that we can move <font color="blue"> slider left and right </font> to see the comparison.    
        </p>
        <br> 
        <div class="parent-video-compare-container">
            <div class="b-dics", style="width: 100%; font-weight: 600;">
                <img src="resources/teaser_details/detailed_files/pcd/test_01_sample_8116_0.png" alt="Input point cloud">
                <img src="resources/teaser_details/detailed_files/pointnerf/0000000000.png" alt="PointNeRF">
                <img src="resources/teaser_details/detailed_files/our/0000000000.png" alt="PointNeRF++ (Ours)">
                <img src="resources/teaser_details/detailed_files/nerf/0000000000.png" alt="NeRF">
            </div>
        </div>
        <br> 
        <br> 
        <hr>
        <h1>More Rendering Results</h1>
       
        <table class="tbl_video">
            <tr>
                <td colspan="3" style="background-color: #85b2df; font-size: 20px;">
                   Camera frames (Left camera) in KITTI-360.  
                </td>
            </tr>
            <tr>
                <td colspan="3">
                    <video class="kitti360" id="00" width="100%" preload="auto" playsinline webkit-playsinline loop autoplay muted>
                        <source src="resources/kitti360_quali/00/stack_video_half_size.mp4" type="video/mp4">
                    </video>
                </td>
            </tr>
            <tr>
                <td colspan="3">
                    <video class="kitti360" id="01" width="100%" preload="auto" playsinline webkit-playsinline loop autoplay muted>
                        <source src="resources/kitti360_quali/01/stack_video_half_size.mp4" type="video/mp4">
                    </video>
                </td>
            </tr>
            <tr>
                <td colspan="3">
                    <video class="kitti360" id="02" width="100%" preload="auto" playsinline webkit-playsinline loop autoplay muted>
                        <source src="resources/kitti360_quali/02/stack_video_half_size.mp4" type="video/mp4">
                    </video>
                </td>
            </tr>
            <tr>
                <td colspan="3">
                    <video class="kitti360" id="03" width="100%" preload="auto" playsinline webkit-playsinline loop autoplay muted>
                        <source src="resources/kitti360_quali/03/stack_video_half_size.mp4" type="video/mp4">
                    </video>
                </td>
            </tr>
            <tr>
                <td colspan="3">
                    <video class="kitti360" id="04" width="100%" preload="auto" playsinline webkit-playsinline loop autoplay muted>
                        <source src="resources/kitti360_quali/04/stack_video_half_size.mp4" type="video/mp4">
                    </video>
                </td>
            </tr>
            <tr>
                <td width=33.33% style="font-size: 18px;"> Point cloud at <br> image's viewpoint</td>
                <td width=33.33% style="font-size: 18px;"> PointNeRF</td>
                <td width=33.33% style="font-size: 18px;"> PointNeRF++ (Ours) </td>
            </tr>
        </table>
        
        <table class="tbl_video">
            <tr>
                <td colspan="3" style="background-color: #85b2df; font-size: 20px;">
                   <span style="color: red;">Densely interpolated</span> frames in KITTI-360   
                </td>
            </tr>
            <tr>
                <td colspan="3">
                    <video class="kitti360dense" id="00" width="100%" preload="auto" playsinline webkit-playsinline loop autoplay muted>
                        <source src="resources/kitti360_quali_dense/00/output_stacked_compressed_half_size_noptsnerf_compressed.mp4" type="video/mp4">
                    </video>
                </td>
            </tr>
            <tr>
                <td colspan="3">
                    <video class="kitti360dense" id="01" width="100%" preload="auto" playsinline webkit-playsinline loop autoplay muted>
                        <source src="resources/kitti360_quali_dense/01/output_stacked_compressed_half_size_noptsnerf_compressed.mp4" type="video/mp4">
                    </video>
                </td>
            </tr>
            <tr>
                <td colspan="3">
                    <video class="kitti360dense" id="02" width="100%" preload="auto" playsinline webkit-playsinline loop autoplay muted>
                        <source src="resources/kitti360_quali_dense/02/output_stacked_compressed_half_size_noptsnerf_compressed.mp4" type="video/mp4">
                    </video>
                </td>
            </tr>
            <tr>
                <td colspan="3">
                    <video class="kitti360dense" id="03" width="100%" preload="auto" playsinline webkit-playsinline loop autoplay muted>
                        <source src="resources/kitti360_quali_dense/03/output_stacked_compressed_half_size_noptsnerf_compressed.mp4" type="video/mp4">
                    </video>
                </td>
            </tr>
            <tr>
                <td colspan="3">
                    <video class="kitti360dense" id="04" width="100%" preload="auto" playsinline webkit-playsinline loop autoplay muted>
                        <source src="resources/kitti360_quali_dense/04/output_stacked_compressed_half_size_noptsnerf_compressed.mp4" type="video/mp4">
                    </video>
                </td>
            </tr>
            <tr>
                <td width=33.33% style="font-size: 18px;"> Point cloud at <br> image's viewpoint</td>
                <td width=33.33% style="font-size: 18px;"> Depth map</td>
                <td width=33.33% style="font-size: 18px;"> Color </td>
            </tr>
        </table>
        
       
        <table class="tbl_video">
            <tr>
                <td colspan="4" style="background-color: #85b2df; font-size: 20px;">
                   More frames in ScanNet. 
                </td>
            </tr>
            <tr>
                <td colspan="4">
                    <video width="100%" preload="auto" playsinline webkit-playsinline loop autoplay muted>
                        <source src="resources/scannet_quali/0101_04/compressed_stack_half_size.mp4" type="video/mp4">
                    </video>
                </td>
            </tr>
            <!-- <tr>
                <td colspan="4">
                    <video width="100%" preload="auto" playsinline webkit-playsinline loop autoplay muted>
                        <source src="resources/scannet_quali/0241_01/compressed_stack_half_size.mp4" type="video/mp4">
                    </video>
                </td>
            </tr> -->
            <tr>
                <td width=25% style="font-size: 18px;"> Point cloud at <br> image's viewpoint</td>
                <td width=25% style="font-size: 18px;"> PointNeRF</td>
                <td width=25% style="font-size: 18px;"> PointNeRF++ (Ours) </td>
                <td width=25% style="font-size: 18px;"> Ground Truth </td>
            </tr>
        </table> 
        <table class="tbl_video">
            <tr>
                <td colspan="8" style="background-color: #85b2df; font-size: 20px;">
                   Rendering across scales  
                </td>
            </tr>
            <tr>
                <td colspan="8">
                    <video width="100%" preload="auto" playsinline webkit-playsinline loop autoplay muted>
                        <source src="resources/scannet_scales/350_390/output_stacked_half_size.mp4" type="video/mp4">
                    </video>
                </td>
            </tr>
            <tr>
                <td colspan="8">
                    <video width="100%" preload="auto" playsinline webkit-playsinline loop autoplay muted>
                        <source src="resources/scannet_scales/983_998/output_stacked_half_size.mp4" type="video/mp4">
                    </video>
                </td>
            </tr>
            <tr>
                <td width=12.5% style="font-size: 18px; vertical-align: top; "> Point cloud at <br> image's viewpoint</td>
                <td width=12.5% style="font-size: 18px; vertical-align: top; "> Level 0 <br> (Global level)</td>
                <td width=12.5% style="font-size: 18px; vertical-align: top; "> Level 1 </td>
                <td width=12.5% style="font-size: 18px; vertical-align: top; "> Level 2 </td>
                <td width=12.5% style="font-size: 18px; vertical-align: top; "> Level 3 </td>
                <td width=12.5% style="font-size: 18px; vertical-align: top; "> Level 4 <br> (Fine level) </td>
                <td width=12.5% style="font-size: 18px; vertical-align: top; "> All levels </td>
                <td width=12.5% style="font-size: 18px; vertical-align: top; "> Ground Truth </td>
            </tr>
        </table> 

        <hr>
        <h1>Acknowledgements</h1> 
            <p style="width: 80%;text-align: justify;">
            This work was supported in part by the Natural Sciences and Engineering Research Council of Canada (NSERC) Discovery Grant, NSERC Collaborative Research and Development Grant, Google, Digital Research Alliance of Canada, and Advanced Research Computing at the University of British Columbia.
            <br><br>
            This website is adapted from the template was originally made by <a href="http://web.mit.edu/phillipi/">Phillip Isola</a>. 
            This template was originally made by <a href="http://web.mit.edu/phillipi/">Phillip Isola</a> and <a href="http://richzhang.github.io/">Richard Zhang</a> for a <a href="http://richzhang.github.io/colorization/">colorful project</a>, and inherits the modifications made by <a href="https://github.com/elliottwu/webpage-template">Shangzhe Wu</a> 
            and  <a href="https://github.com/canonical-capsules/canonical-capsules.github.io">Canonical Capsules</a>.

            Video comparison is adapted from <a href="https://jonbarron.info/zipnerf">ZipNeRF</a>. 
            Image slider script is adapted from  <a href="https://github.com/abelcabezaroman/definitive-image-comparison-slider">Dics</a>. 
            The code can be found <a href="https://github.com/pointnerfpp/pointnerfpp.github.io">here</a>.
            </p>

    <br><br>
    </div>

    <script>
        document.addEventListener('DOMContentLoaded', function () {
            // Get all video elements with the class 'myVideo'
            var videos = document.querySelectorAll('.kitti360');
    
            // Set the playback rate for each video
            videos.forEach(function(video) {
                video.playbackRate = 0.3; // Adjust the playback rate as needed
            });

            new Dics({
                container: document.querySelectorAll('.b-dics')[0],
                hideTexts: false,
                textPosition: "bottom",
                // linesColor: 'rgb(0,0,0)'
            });
            new Dics({
                container: document.querySelectorAll('.b-dics')[1],
                hideTexts: false,
                textPosition: "bottom"
            });
        });
        initComparisons();
    </script>
    <br><br><br>

</body>

</html>
